## 📘  什么是零拷贝？

**零拷贝 (Zero-Copy)** 技术的核心目标是**最大限度地减少或完全消除在数据从一个存储区域（如磁盘）移动到另一个存储区域（如网络接口卡）的过程中，CPU 进行的不必要的数据拷贝操作**。

需要明确的是，“零”并非指完全没有数据拷贝（例如，数据从硬件（磁盘）到内存的初始 DMA 拷贝通常是无法避免的），而是指**尽可能避免在内核空间与用户空间之间，以及内核空间内部各缓冲区之间发生 CPU 参与的数据复制**。

## 🧠 为什么需要零拷贝？

采用零拷贝技术的主要原因包括：

1.  **减少 CPU 开销**：数据拷贝是一项消耗 CPU 计算周期的任务。将 CPU 从这些任务中解放出来，可以使其执行更多应用程序的核心逻辑，从而提升整体性能。
2.  **降低内存带宽消耗**：频繁的数据拷贝会占用宝贵的内存总线带宽。减少拷贝次数能够有效降低对内存带宽的竞争，这对于内存带宽敏感的系统尤为重要。
3.  **减少上下文切换**：一些零拷贝技术通过优化数据路径，减少了内核态和用户态之间的切换次数，进一步提升了处理效率。
4.  **提高应用程序性能**：对于 I/O 密集型应用，如 Web 服务器、文件服务器、消息队列、流媒体服务器等，零拷贝技术能够显著提升数据传输的效率和整体吞吐量。

## 常见的零拷贝技术和实现方式

不同的操作系统和编程环境提供了多样的零拷贝或近似零拷贝的实现机制。以下是一些主流的技术：

### 1. `mmap()` (内存映射文件) + `write()`

* **工作原理**：
    * `mmap()` 系统调用可以将文件的内容直接映射到应用程序的用户地址空间。这意味着应用程序可以像访问内存一样直接操作内核的页缓存 (Page Cache) 中的数据，无需将数据从内核空间拷贝到用户空间。
    * 当应用程序需要发送这些数据时，它可以直接调用 `write()` (或 `send()`) 系统调用。内核可以直接将页缓存中的数据发送到目标（例如网络套接字缓冲区），再由 DMA 控制器发送到网卡。
* **拷贝次数**：
    * 相较于传统方式，此方法省去了“内核缓冲区 -> 用户缓冲区”的 CPU 拷贝。
    * 如果数据已存在于页缓存中，从磁盘到用户可操作的内存几乎没有 CPU 拷贝。
    * 从用户（实际上是内核的页缓存）到网络套接字缓冲区可能仍有一次内核内部拷贝（取决于具体实现和硬件支持），然后是 DMA 到网卡。
* **优点**：
    * 减少了一次关键的 CPU 数据拷贝。
    * 允许应用程序以内存访问的方式处理文件内容。
* **缺点**：
    * 文件大小受限于进程的地址空间大小。
    * 文件映射可能导致潜在的缺页中断开销。
    * 对于小文件，`mmap()` 的设置开销可能超过其带来的收益。
	 
![mmap](/image/computer/mmap.png)

### 2. `sendfile()` (Linux 系统调用)

* **工作原理**：
    * `sendfile()` 是一个专门设计用于在两个文件描述符之间高效传输数据的系统调用，尤其适用于将文件内容直接发送到网络套接字。其操作完全在内核空间内完成。
    1.  `sendfile()` 调用指示内核将数据直接从内核的页缓存通过 DMA 拷贝到与目标套接字关联的内核缓冲区。
    2.  在支持“分散/收集 (scatter-gather) DMA”的硬件上，甚至可以避免这次内核内部的拷贝，直接将页缓存中的数据描述符传递给网卡。
    3.  最终数据通过 DMA 从套接字缓冲区（或直接从页缓存）拷贝到网络接口卡。
* **拷贝次数**：
    * 理想情况下（特别是当网卡支持 scatter-gather DMA 时），数据仅发生两次 DMA 拷贝：磁盘 -> 页缓存，页缓存 -> 网卡。CPU 不参与数据内容的物理拷贝。
    * 如果网卡不支持 scatter-gather DMA，则可能存在一次从页缓存到套接字缓冲区的内核内部 CPU 拷贝。
    * 它完全避免了数据在用户空间和内核空间之间的拷贝。
* **优点**：
    * 极大地减少了 CPU 拷贝次数和上下文切换次数（应用层只需一次系统调用）。
    * 效率非常高，是静态文件服务器等场景的理想选择。
* **缺点**：
    * 功能相对固定，主要用于文件到套接字或文件到文件的传输。
    * 数据在传输过程中不能被应用程序修改。
![sendfile](/image/computer/sendfile1.png)	
	
### 3. 带有 Scatter/Gather DMA 的 `sendfile()`

* 当网络接口卡 (NIC) 硬件支持 Scatter/Gather DMA 时，`sendfile()` 的效率能得到进一步提升。
* 内核可以将页缓存中多个不连续的内存数据块的地址和长度信息列表直接传递给网卡。
* 网卡硬件随后可以直接从这些分散的内存位置收集数据并组装成网络包进行发送，从而避免了内核将这些分散的数据块拷贝到一个连续的套接字缓冲区的步骤。	

![sendfile-Scatter/Gather](/image/computer/sendfile2.png)	

### 4. `splice()` (Linux 系统调用)

* **工作原理**：
    * `splice()` 可以在两个文件描述符之间移动数据，其中至少有一个必须是管道 (pipe) 文件描述符。（管道（pipe）文件描述符是一种特殊类型的文件描述符，用于实现**进程间通信（IPC）**或在内核中**缓存和转发数据流**。它代表一个**内核缓冲区**，数据写入管道的一端，另一端可以读取。）
    * 它通过在内核中重新调整指向数据页的指针（即修改缓冲区描述符）来实现数据“移动”，而不需要实际拷贝数据内容。
* **拷贝次数**：
    * 可以实现真正意义上的内核内部零拷贝（没有数据内容的物理复制）。数据从输入文件描述符关联的内核缓冲区“逻辑上”直接移动到输出文件描述符关联的内核缓冲区。
* **优点**：
    * 效率极高，实现了内核内部的数据零拷贝。
    * 比 `sendfile` 更灵活，可用于更广泛的数据流重定向场景。
* **缺点**：
    * 使用上可能比 `sendfile` 更复杂，通常需要借助管道作为中介。

#### ✅ 管道的基本特性：

- 管道是**单向**的（普通 pipe），但可以通过两个管道实现双向通信。
- 管道在内核中维护一个缓冲区，通常用于在不同进程、线程或系统调用之间传递数据。
- 管道的本质是一对文件描述符：
  - 一个用于读（read end）
  - 一个用于写（write end）	

![splice](/image/computer/splice.png)

### 5. `tee` 系统调用 (Linux)

* **工作原理**：
    `tee` 系统调用将数据从一个管道（输入文件描述符 `fd_in` 必须是一个管道）复制到另一个管道（输出文件描述符 `fd_out` 必须是一个管道）。重要的是，当数据从 `fd_in` 读出并写入 `fd_out` 时，数据**仍然保留在 `fd_in` 中**，就像它没有被消耗一样。这使得数据可以被后续的 `splice` 调用从 `fd_in` 再次读取并发送到另一个目的地（例如一个文件或套接字）。
    它实际上是将管道中的数据“复制”了一份到另一个管道，而原管道中的数据看上去没有变化，可以继续被使用。

* **零拷贝特性**：
    与 `splice` 类似，`tee` 的操作完全在内核空间进行。它通过操纵内核中的页面引用（page references）和缓冲区描述符来实现数据的“复制”，而不是进行实际的数据内容拷贝。这意味着数据不需要在内核空间和用户空间之间来回传递，也不需要在内核空间内部进行不必要的物理拷贝。

* **与 `splice` 的关系与典型用法**：
    `tee` 和 `splice` 往往协同工作：
    1.  数据源（例如一个文件或网络套接字）通过 `splice()` 系统调用将数据“零拷贝”地读入到一个管道中 (称之为 `pipe_A_in`)。
    2.  然后，可以使用 `tee(pipe_A_in, pipe_B_out, len, flags)` 将 `pipe_A_in` 中的数据复制到另一个管道 `pipe_B_out`。此时，`pipe_A_in` 中的数据仍然存在。
    3.  接下来：
        * `pipe_A_in` 中的数据可以通过另一次 `splice()` 调用发送到最终目的地（例如一个网络套接字）。
        * `pipe_B_out` 中的数据也可以通过 `splice()` 调用发送到另一个目的地（例如一个本地日志文件）。

    通过这种方式，一份数据流可以被高效地分发到两个不同的目的地，整个过程都尽可能地在内核态完成，避免了多次数据拷贝。

* **优点**：
    * 在内核中高效地复制（逻辑上）和分发数据流。
    * 避免了用户空间和内核空间之间以及内核内部不必要的数据拷贝。
    * 允许一份数据被多个消费者使用而无需多次读取源数据。

* **使用场景**：
    * 需要将数据流同时发送到多个目的地，例如，一个网络套接字用于实时传输，同时另一个管道用于本地存档或进一步处理。
    * 在复杂的数据处理流水线中，需要在内核中对数据进行分流或复制。
	

## 总结一下零拷贝的好处

* **显著的性能提升**：尤其是在处理大文件传输或高并发网络I/O时。
* **CPU 资源释放**：CPU 可以专注于执行应用程序的业务逻辑，而不是耗费在数据搬运上。
* **降低延迟**：数据传输路径更短，处理环节更少。

## 如何选择零拷贝技术？

选择哪种零拷贝技术取决于具体的应用场景、操作系统的支持程度以及数据在传输过程中是否需要被应用程序修改等因素：

* 对于**静态文件 Web 服务器**或类似场景，`sendfile()` 通常是最佳选择。
* 如果需要在**发送前访问或修改数据**，`mmap()` + `write()` 可能更为合适。
* 若需在**内核中进行复杂的数据流重定向或处理**，`splice()` 提供了强大的能力。
* 若需在**将数据流分发到多个地方**，`tee()+ splice()` 提供了强大的能力。
* 对于有**自定义高级缓存管理机制的应用程序**（如数据库），直接 I/O 可能是一种选择。

在 Java 领域，NIO (New Input/Output) 包中的 `FileChannel.transferTo()` 和 `FileChannel.transferFrom()` 方法，其底层实现就可能利用了操作系统的 `sendfile()` 或类似的零拷贝机制（具体取决于操作系统和 JVM 的实现）。

理解零拷贝技术的关键在于认识到它是一种通过借助操作系统特性和硬件能力，来智能地管理和优化数据在不同内存区域间流动的方式，其核心目的在于避免不必要的 CPU 介入和数据内容复制，从而提升I/O性能。